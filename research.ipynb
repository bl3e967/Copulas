{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["![QuantConnect Logo](https://cdn.quantconnect.com/web/i/icon.png)\n", "<hr>"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["# QuantBook Analysis Tool \n", "# For more information see [https://www.quantconnect.com/docs/research/overview]\n", "qb = QuantBook()\n", "spy = qb.AddEquity(\"SPY\")\n", "\n", "index_ticker = \"SPY\"\n", "index_etf = [index_ticker]\n", "symdict = {}\n", "for ticker in index_etf: \n", "    symdict[ticker] = qb.AddEquity(ticker) \n", "\n", "ystart = 2006\n", "n_years = 10\n", "n_train_days = 252*2\n", "start, end = datetime(ystart,1,11,9,30,0), datetime(ystart+n_years, 1, 1, 16,30,0)    \n", "res = Resolution.Hour\n", "index_history = qb.History(index_etf, start, end, res)\n", "# tickers = history.index.get_level_values(level=0).unique()\n", "index_close = index_history['close'].unstack(level=0)\n", "index_close"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["def min_max_df_scale(df):\n", "    res = (df - df.min())/(df.max()-df.min())\n", "    return res \n", "\n", "def norm_df_scale(df): \n", "    res = (df - df.mean()) / df.std()\n", "    return res \n", "\n", "def rel_norm_df_scale(df):\n", "    res = (df - df.iloc[0]) / df.std()\n", "    return res \n", "\n", "def rel_log_df_scale(df): \n", "    res = np.log(df / df.iloc[0])\n", "    return res \n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We investigate relationships between assets and their corresponding market index. "]}, {"cell_type": "code", "execution_count": 3, "metadata": {"scrolled": true}, "outputs": [], "source": ["# tickers = [\"MSFT\", \"GOOGL\", \"AAPL\", \"AMZN\", \"FB\", \"JPM\", \"JNJ\", \"KO\", \"PEP\", \"WFC\", \"C\", \"IBM\"]\n", "tickers = [\"XLK\", \"VGT\", \"IYW\", \"FTEC\", \"IGV\"]\n", "securities = []\n", "for ticker in tickers: \n", "    securities.append(qb.AddEquity(ticker))\n", "\n", "history = qb.History(tickers, start, end, res)\n", "# tickers = history.index.get_level_values(level=0).unique()\n", "\n", "close = history['close'].unstack(level=0) # instrument close\n", "close[\"SPY\"] = index_close.mean(axis=1) # average over rows, not columns \n", "\n", "# normalize price values\n", "norm_close = norm_df_scale(close)\n", "# get returns\n", "# returns = np.log(close / close.shift(1))#.dropna()\n", "returns = np.log(close/close.shift(1))#.dropna(axis=1,how='all').dropna(axis=0,how='any')\n", "\n", "# -- plots --\n", "norm_close.plot(figsize=(20,10)) # plot timeseries\n", "plt.grid()\n", "\n", "returns.plot(figsize=(20,10)) # plot returns \n", "plt.grid()\n"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": ["import matplotlib.cm as cm \n", "name = \"XLK\"\n", "ticker = name + \" 2T\" \n", "\n", "norm_close[[ticker, \"SPY 2T\"]].plot(figsize=(20,10))\n", "returns[[ticker, \"SPY 2T\"]].plot(figsize=(20,10))\n", "\n", "sec = returns[ticker].values\n", "markt = returns[\"SPY 2T\"].values\n", "\n", "assert len(sec) == len(markt)\n", "plt.figure(figsize=(20,10))\n", "colours = cm.rainbow(np.linspace(0,1,len(sec)))\n", "plt.scatter(sec, markt, c=colours, marker='x', s=5)\n", "\n", "plt.grid()\n", "plt.xlabel(name)\n", "plt.ylabel('SPY')\n"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": ["# get correlations for first year's worth of data \n", "returns_end = returns.index[0] + timedelta(days=365*2)\n", "returns_corr_spearman = returns.loc[returns.index < returns_end].corr(method=\"spearman\")\n", "returns_corr_spearman.style.background_gradient(cmap='inferno') # plot correlation"]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": ["# get correlations for first year's worth of data \n", "returns_end = returns.index[0] + timedelta(days=365*2)\n", "returns_corr_kendall = returns.loc[returns.index < returns_end].corr(method=\"kendall\")\n", "returns_corr_kendall.style.background_gradient(cmap='inferno') # plot correlation"]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [], "source": ["# base ticker\n", "base_ticker = \"SPY 2T\"\n", "\n", "# get high correlation assets \n", "corr = returns_corr_kendall\n", "high_corr_tickers = corr[base_ticker][(corr[base_ticker] >= 0.5) & (corr[base_ticker] < 1)].index\n", "high_corr_df = norm_close[high_corr_tickers]\n", " \n", "n_plots = 3\n", "n_assets = len(high_corr_tickers)\n", "fig, ax = plt.subplots(n_assets, n_plots, figsize=(20,10*n_assets))\n", "print(n_assets)\n", "for i, col in enumerate(high_corr_df.columns): \n", "    indices = norm_close.index\n", "    market = norm_close[base_ticker].values\n", "    asset = high_corr_df[col].values\n", "    \n", "    if n_assets > 1: \n", "        ax[i,0].plot(norm_close.index[0:n_train_days], market[0:n_train_days], c='r', linestyle='-')\n", "        ax[i,0].plot(norm_close.index[0:n_train_days], asset[0:n_train_days], c='b', linestyle='-')\n", "        \n", "        ax[i,0].plot(norm_close.index[n_train_days:-1], market[n_train_days:-1], c='r', linestyle=':')\n", "        ax[i,0].plot(norm_close.index[n_train_days:-1], asset[n_train_days:-1], c='b', linestyle=':')\n", "        \n", "        ax[i,0].grid()\n", "        ax[i,0].legend([base_ticker, col])\n", "\n", "        spread = (norm_close[base_ticker] - high_corr_df[col]).dropna()\n", "        ax[i,1].plot(spread.index[0:n_train_days],spread.values[0:n_train_days], c='g', linestyle='-')\n", "        ax[i,1].plot(spread.index[n_train_days:-1],spread.values[n_train_days:-1], c='g', linestyle=':')\n", "        ax[i,1].grid()\n", "    \n", "        ax[i,2].scatter(returns[base_ticker].values, returns[col].values, s=3, marker='x')\n", "        ax[i,2].grid() \n", "        ax[i,2].set_xlabel(base_ticker)\n", "        ax[i,2].set_ylabel(col)\n", "        \n", "    else: \n", "        ax[0].plot(norm_close.index[0:n_train_days], market[0:n_train_days], c='r', linestyle='-')\n", "        ax[0].plot(norm_close.index[n_train_days:-1], market[n_train_days:-1], c='r', linestyle=':')\n", "        ax[0].plot(norm_close.index[0:n_train_days], asset[0:n_train_days], c='b', linestyle='-')\n", "        ax[0].plot(norm_close.index[n_train_days:-1], asset[n_train_days:-1], c='b', linestyle=':')\n", "        ax[0].grid()\n", "        ax[0].legend([base_ticker, col])\n", "\n", "        spread = (norm_close[base_ticker] - high_corr_df[col]).dropna()\n", "        ax[1].plot(spread.index,spread.values, c='g')\n", "        ax[1].grid()\n", "        \n", "        ax[2].scatter(returns[base_ticker].values, returns[col].values, s=3, marker='x')\n", "        ax[2].grid() \n", "        ax[2].set_xlabel(base_ticker)\n", "        ax[2].set_ylabel(col)\n", "        \n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We try and model the marginal distributions"]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [], "source": ["from scipy.stats import t, laplace\n", "\n", "distribution = laplace\n", "# ----------------------------------------------------------------------------------------------------\n", "# index \n", "# ----------------------------------------------------------------------------------------------------\n", "def plot_kde_vs_dist(some_returns, ax=None, title=None):\n", "    # fit kde \n", "    if ax is None: \n", "        ax = some_returns.hist(figsize=(20,10), bins=500, density=True)\n", "    else: \n", "        some_returns.hist(figsize=(20,10), bins=500, density=True, ax=ax)\n", "    \n", "    some_returns.plot.kde(linestyle='-', linewidth=3, ax=ax)\n", "\n", "    # fit t distribution\n", "    par = distribution.fit(some_returns.dropna())\n", "    print(f\"Distribution ML parametrs:{par}\")\n", "    r = distribution.rvs(*par, 2000)\n", "    r = pd.DataFrame(r)\n", "    r.plot.kde(linestyle='--', linewidth=3, ax=ax)\n", "\n", "    ax.legend(['KDE', str(distribution)])\n", "    ax.set_xlim([-0.025,0.025])\n", "    ax.grid()\n", "    ax.set_title(title)\n", "    \n", "def compare_dist_plot(returns_list, legend_list=None): \n", "    fig, ax = plt.subplots(1,1, figsize=(20,10))\n", "    for returns in returns_list: \n", "        r = returns.dropna(axis=1,how='all').dropna(axis=0,how='any')\n", "        if len(r) > 0: \n", "            par = distribution.fit(r)    \n", "            print(f\"Distribution ML parametrs: {par}\")\n", "            r = distribution.rvs(*par, 2000)\n", "            r = pd.DataFrame(r)\n", "            r.plot.kde(linestyle='--', linewidth=3, ax=ax)\n", "    \n", "    ax.legend(legend_list) \n", "    ax.set_xlim([-0.025, 0.025])\n", "    \n", "\n", "fig, ax = plt.subplots(1,2, figsize=(40,40), sharex=True, sharey=True)\n", "    \n", "some_returns = {\n", "    '24months' : returns.loc[returns.index[0]:returns.index[0]+pd.offsets.DateOffset(months=24)], \n", "    '12months' : returns.loc[returns.index[0]:returns.index[0]+pd.offsets.DateOffset(months=12)], \n", "    '6months' : returns.loc[returns.index[0]:returns.index[0]+pd.offsets.DateOffset(months=6)], \n", "    '3months' : returns.loc[returns.index[0]:returns.index[0]+pd.offsets.DateOffset(months=3)], \n", "}\n", "\n", "plot_kde_vs_dist(some_returns['24months']['SPY 2T'], ax[0], title=\"24 Months\")\n", "plot_kde_vs_dist(some_returns['12months']['SPY 2T'], ax[1], title=\"12 Months\")\n", "\n", "returns_lst = [val[1] for val in some_returns.items()]\n", "legend_lst  = [val[0] for val in some_returns.items()]\n", "compare_dist_plot(returns_lst, legend_lst)\n"]}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [], "source": ["# In general, t-distribution does not seem to be a good fit. \n", "for ticker in high_corr_tickers: \n", "    fig, ax = plt.subplots(1,2, figsize=(40,40), sharex=True, sharey=True)\n", "\n", "    some_returns = {\n", "        '24months' : returns.loc[returns.index[0]:returns.index[0]+pd.offsets.DateOffset(months=120)], \n", "        '12months' : returns.loc[returns.index[0]:returns.index[0]+pd.offsets.DateOffset(months=12)], \n", "        '6months' : returns.loc[returns.index[0]:returns.index[0]+pd.offsets.DateOffset(months=6)], \n", "        '3months' : returns.loc[returns.index[0]:returns.index[0]+pd.offsets.DateOffset(months=3)], \n", "    }\n", "\n", "    plot_kde_vs_dist(some_returns['24months']['SPY 2T'], ax[0], title=\"24 Months for \"+str(ticker))\n", "    plot_kde_vs_dist(some_returns['12months']['SPY 2T'], ax[1], title=\"12 Months for \"+str(ticker))\n", "\n", "    returns_lst = [val[1] for val in some_returns.items()]\n", "    legend_lst  = [val[0] for val in some_returns.items()]\n", "    compare_dist_plot(returns_lst, legend_lst)\n"]}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [], "source": ["# fit index marginal with student-t distribtion\n", "index_params = distribution.fit(returns['SPY 2T'].dropna())\n", "print(\"Index parameters: {}\".format(*index_params))\n", "index_cdf = distribution.cdf(returns['SPY 2T'].dropna(), *index_params)\n", "\n", "# fit amazon marginal with student-t distribtion \n", "ticker = \"XLK 2T\"\n", "asset_params = distribution.fit(returns[ticker].dropna())\n", "print(ticker + \" parameters: {}\".format(*asset_params))\n", "asset_cdf = distribution.cdf(returns[ticker].dropna(), *asset_params)\n", "\n", "print(f\"{len(index_cdf)},{len(asset_cdf)}\")\n", "plt.figure(figsize=(10,10))\n", "plt.scatter(index_cdf, asset_cdf, s=0.9)\n", "plt.xlabel(\"Index\")\n", "plt.ylabel(ticker)\n", "plt.grid()"]}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [], "source": ["# rather than use a parametric distribution, use empirical cdf function instead\n", "# assuming we have enouh data\n", "from statsmodels.distributions.empirical_distribution import ECDF\n", "\n", "# [\"XLK\", \"VGT\", \"IYW\", \"FTEC\", \"IGV\"]\n", "index_ticker = \"SPY 2T\"\n", "index_data = returns[index_ticker].dropna()\n", "index_dist = ECDF(index_data) # initialise empirical cdf with data\n", "index_cdf = index_dist(index_data)\n", "\n", "asset_ticker = \"XLK 2T\"\n", "asset_data = returns[asset_ticker].dropna()\n", "asset_dist = ECDF(asset_data)\n", "asset_cdf = asset_dist(asset_data)\n", "\n", "print(f\"{len(index_cdf)},{len(asset_cdf)}\")\n", "plt.figure(figsize=(10,10))\n", "plt.scatter(index_cdf, asset_cdf, s=0.9)\n", "plt.xlabel(\"Index\")\n", "plt.ylabel(ticker)\n", "plt.grid()\n"]}, {"cell_type": "code", "execution_count": 12, "metadata": {}, "outputs": [], "source": ["import sys \n", "from scipy.integrate import quad as integrate\n", "from scipy.optimize import minimize\n", "\n", "def ClaytonCdf(u,v,theta):\n", "    if (V == 0).all() or (U == 0).all():\n", "        cdf = np.zeros(V.shape[0])\n", "    else:\n", "        cdfs = [\n", "            np.power(\n", "                np.power(U[i], -theta) + np.power(V[i], -theta) - 1,\n", "                -1.0 / theta\n", "            )\n", "            if (U[i] > 0 and V[i] > 0) else 0\n", "            for i in range(len(U))\n", "        ] # take into account 0 value\n", "\n", "        cdf = np.array(cdfs)\n", "    \n", "    return cdf\n", "\n", "def GumbelCdf(U,V,theta):\n", "    \n", "    if theta == 1:\n", "        cdf = np.multiply(U, V)\n", "    else:\n", "        h = np.power(-np.log(U), theta) + np.power(-np.log(V), theta)\n", "        h = -np.power(h, 1.0 / theta)\n", "        cdf = np.exp(h)\n", "    \n", "    return cdf \n", "\n", "def FrankCdf(u,v,theta): \n", "    num = np.multiply(\n", "        np.exp(np.multiply(-theta, U)) - 1,\n", "        np.exp(np.multiply(-theta, V)) - 1\n", "    )\n", "    den = np.exp(-theta) - 1\n", "\n", "    return -1.0 / theta * np.log(1 + num / den)\n", "\n", "def ClaytonPdf(U,V,theta):\n", "    a = (theta + 1) * np.power(np.multiply(U, V), -(theta + 1))\n", "    b = np.power(U, -theta) + np.power(V, -theta) - 1\n", "    c = -(2 * theta + 1) / theta\n", "    return a * np.power(b, c)\n", "\n", "def GumbelPdf(U,V,theta): \n", "    \n", "    if theta == 1:\n", "            pdf =  np.multiply(U, V)\n", "    else:\n", "        a = np.power(np.multiply(U, V), -1)\n", "        tmp = np.power(-np.log(U), theta) + np.power(-np.log(V), theta)\n", "        b = np.power(tmp, -2 + 2.0 / theta)\n", "        c = np.power(np.multiply(np.log(U), np.log(V)), theta - 1)\n", "        d = 1 + (theta - 1) * np.power(tmp, -1.0 / theta)\n", "        \n", "        pdf =  GumbelCdf(U,V,theta) * a * b * c * d\n", "        \n", "    return pdf \n", "\n", "def FrankPdf(u,v,theta):\n", "    \n", "    _A = lambda z : np.exp(np.multiply(theta, z)) - 1\n", "    \n", "    if theta == 0:\n", "        pdf = np.multiply(U, V)\n", "\n", "    else:\n", "        num = np.multiply(np.multiply(-theta, _A(1)), 1 + _A(np.add(U, V)))\n", "        aux = np.multiply(_A(U), _A(V)) + _A(1)\n", "        den = np.power(aux, 2)\n", "        pdf =  num / den\n", "    \n", "    return pdf\n", "\n", "def GumbelConditionalPdf(u,given_v,theta):\n", "    \n", "    v = given_v\n", "    C = GumbelPdf(u,given_v,theta)\n", "    K = ((-np.log(u))**theta + (-np.log(v))**theta)**((1-theta)/theta)\n", "    Q = (-np.log(v))**(theta-1)/v\n", "    res = C*K*Q\n", "    \n", "    return res \n", "\n", "def ClaytonConditionalPdf(u,given_v,theta):\n", "    v = given_v\n", "    K = (u**(-theta)+v**(-theta)-1)**(1/theta-1)\n", "    res = v**(-theta-1)*K\n", "    return res\n", "\n", "def FrankConditionalPdf(u, given_v, theta):\n", "    v = given_v\n", "    f = lambda: np.exp(-x) - 1\n", "    \n", "    den = f(theta*u)*f(theta*v)+f(theta)\n", "    num = f(theta*u)*f(theta*v) + f(theta*u)\n", "    \n", "    res = num/den \n", "    \n", "    return res \n", "    \n", "\n", "class ArchimedeanCopula():\n", "    def __init__(self, family, tau): \n", "        \n", "        self._theta_func = {\n", "            'Gumbel' : self._gumbel_theta(tau),\n", "            'Clayton': 2*tau/(1-tau),\n", "            'Frank'  : self._frank_theta(tau)\n", "        }\n", "        \n", "        self._pdf_func = {\n", "            'Gumbel' : GumbelPdf, \n", "            'Clayton': ClaytonPdf, \n", "            'Frank'  : FrankPdf\n", "        }\n", "        \n", "        self._cdf_func = {\n", "            'Gumbel' : GumbelCdf, \n", "            'Clayton': ClaytonCdf, \n", "            'Frank'  : FrankCdf\n", "        }\n", "        \n", "        self.theta = self._theta_func[family]\n", "        self._pdf = self._pdf_func[family]\n", "        self._cdf = self._cdf_func[family]\n", "    \n", "    def _gumbel_theta(self, tau): \n", "        if tau == 1: \n", "            raise ValueError('Kendall Tau value for Gumbel Copula cannot be 1')\n", "        return 1/(1-tau)\n", "    \n", "    def _frank_theta(self, tau): \n", "        \n", "        # integrand\n", "        integrand = lambda t: t / (np.exp(t) - 1) \n", "        \n", "        # theta function\n", "        frank_fnc = \\\n", "        lambda theta: ((tau -1) / 4. - (integrate(integrand, sys.float_info.epsilon, theta)[0]/theta - 1)) / theta\n", "        theta = minimize(frank_fnc, 4, method='BFGS',tol=1e-5).x\n", "        \n", "        return theta \n", "    \n", "    def pdf(self, u, v):\n", "        return self._pdf(u,v,self.theta)\n", "    \n", "    def cdf(self, u, v):\n", "        return self._cdf(u,v,self.theta)\n", "        "]}, {"cell_type": "code", "execution_count": 13, "metadata": {"scrolled": true}, "outputs": [], "source": ["from scipy.stats import kendalltau\n", "# [\"XLK\", \"VGT\", \"IYW\", \"FTEC\", \"IGV\"]\n", "index_ticker = \"SPY 2T\"\n", "index_data = returns[index_ticker].dropna()\n", "index_dist = ECDF(index_data) # initialise empirical cdf with data\n", "index_cdf = index_dist(index_data)\n", "\n", "asset_ticker = \"XLK 2T\"\n", "asset_data = returns[asset_ticker].dropna()\n", "asset_dist = ECDF(asset_data)\n", "asset_cdf = asset_dist(asset_data)\n", "\n", "tau = kendalltau(asset_data, index_data)\n", "print(f\"{index_ticker} & {asset_ticker} Kendall Tau {tau.correlation}\")"]}, {"cell_type": "code", "execution_count": 14, "metadata": {}, "outputs": [], "source": ["Gumbel = ArchimedeanCopula('Gumbel', tau.correlation)\n", "Clayton = ArchimedeanCopula('Clayton', tau.correlation)"]}, {"cell_type": "code", "execution_count": 15, "metadata": {}, "outputs": [], "source": ["pdfs = Clayton.pdf(asset_cdf, index_cdf)"]}, {"cell_type": "code", "execution_count": 16, "metadata": {"scrolled": true}, "outputs": [], "source": ["from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 unused import\n", "\n", "import matplotlib.pyplot as plt\n", "from matplotlib import cm\n", "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n", "import numpy as np\n", "\n", "copula = Clayton\n", "\n", "fig = plt.figure(figsize=(20,10))\n", "ax = fig.gca(projection='3d')\n", "\n", "theta = 3\n", "\n", "x = np.arange(0.01, 1, 0.01)\n", "y = np.arange(0.01, 1, 0.01)\n", "X,Y = np.meshgrid(x,y)\n", "\n", "Z = np.zeros(X.shape)\n", "for i, u in enumerate(x):\n", "    for j, v in enumerate(y):\n", "        Z[i,j] = copula.pdf(u,v)\n", "\n", "# Plot the surface.\n", "surf = ax.plot_surface(X, Y, Z, cmap=cm.coolwarm,\n", "                       linewidth=0, antialiased=False)\n", "\n", "# Customize the z axis.\n", "ax.zaxis.set_major_locator(LinearLocator(10))\n", "ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n", "angle = -90\n", "ax.view_init(60, angle)\n", "# Add a color bar which maps values to colors.\n", "fig.colorbar(surf, shrink=0.5, aspect=5)\n", "\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.8"}}, "nbformat": 4, "nbformat_minor": 2}