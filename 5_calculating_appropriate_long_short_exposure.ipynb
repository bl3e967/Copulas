{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["![QuantConnect Logo](https://cdn.quantconnect.com/web/i/icon.png)\n", "<hr>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Calculating Appropriate Long/Short Exposure\n", "\n", "We have so far developed a method for estimating the copula density for two assets based on their returns, and a method for calculating the mispricing index from which to generate buy/sell signals. \n", "\n", "What is left is determining the appropriate amount to go long/short on in order to have a dollar-neutral strategy. "]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["#----------------------------------------------------------------------------------------------------\n", "# UTIL FUNCTIONS\n", "#----------------------------------------------------------------------------------------------------\n", "import numpy as np\n", "class Parameter():\n", "    def __init__(self,\n", "                resolution,\n", "                start_year, \n", "                start_month=1, \n", "                start_day=1,\n", "                n_years=0,\n", "                n_months=0, \n", "                n_days=0): \n", "        \n", "        self.Resolution = resolution\n", "        \n", "        end_year = start_year + n_years\n", "        end_month = start_month + n_months\n", "        end_day = start_day + n_days \n", "        self.Start = datetime(start_year,start_month,start_day,9,30,0)\n", "        self.End = datetime(end_year, end_month, end_day,16,30,0)\n", "        \n", "class Data():\n", "    def __init__(self, df):\n", "        self._df = df.dropna()\n", "    \n", "    def __len__(self):\n", "        return len(self._df)\n", "    \n", "    @property \n", "    def prices(self):\n", "        return self._df\n", "    \n", "    @property\n", "    def returns(self):\n", "        return self._df.diff() \n", "    \n", "    @property\n", "    def columns(self):\n", "        return self._df.columns\n", "    \n", "    def plot(self, *args, **kwargs): \n", "        return self._df.plot(*args, **kwargs)\n", "\n", "import random\n", "\n", "def sample_from_bivariate(x_domain, y_domain, weights, n_samples):\n", "    x_domain = x_domain.ravel()\n", "    y_domain = y_domain.ravel()\n", "    weights = np.nan_to_num(weights.ravel()) # account for nans\n", "    \n", "    population = np.array([x_domain, y_domain]).T\n", "    print(population)\n", "    return np.array(random.choices(population, weights, k=n_samples))\n", "\n", "# Utils\n", "def np_remove_nan(x): \n", "    return x[np.logical_not(np.isnan(x).any(axis=1))]\n", "\n", "def np_remove_inf(x):\n", "    return x[np.logical_not(np.isinf(x).any(axis=1))]\n", "\n", "def np_remove_inf_1D(x):\n", "    return x[~np.isinf(x)]\n", "\n", "def np_remove_nan_1D(x):\n", "    return x[~np.isinf(x)]\n", "\n", "# test remove nan \n", "data = np.array([[np.inf,np.inf],\n", "                 [1,2],\n", "                 [1,3],\n", "                 [np.nan, 4],\n", "                 [5,6]])\n", "\n", "data_no_nan = np_remove_nan(data)\n", "data_no_inf = np_remove_inf(data)\n", "data_no_non_num = np_remove_nan(np_remove_inf(data))\n", "\n", "check_for_nan = lambda x: True not in np.isnan(x)\n", "check_for_inf = lambda x: True not in np.isinf(x)\n", "\n", "assert check_for_nan(data_no_nan)\n", "assert check_for_inf(data_no_inf)\n", "assert check_for_nan(data_no_non_num) and check_for_inf(data_no_non_num)\n", "assert data_no_non_num.shape == (3,2)\n"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["#----------------------------------------------------------------------------------------------------\n", "# LOAD DATA\n", "#----------------------------------------------------------------------------------------------------\n", "\n", "print(\"Setting parameters...\")\n", "# parameters\n", "START_YEAR = 2008\n", "START_MONTH = 1\n", "START_DAY = 1\n", "N_YEARS = 1\n", "N_MONTHS = 0\n", "N_DAYS = 0\n", "RESOLUTION = Resolution.Daily\n", "PARAM = Parameter(RESOLUTION, START_YEAR, START_MONTH, START_DAY,\n", "                  N_YEARS, N_MONTHS, N_DAYS)\n", "print(\"Loading QuantBook...\")\n", "qb = QuantBook()\n", "\n", "# Specify list of correlated tickers for S&P 500 \n", "tickers = [\"SPY\",\"XLK\", \"VGT\", \"IYW\", \"IGV\"]\n", "\n", "# register tickers to quantbook\n", "tickers_dict = {}\n", "for ticker in tickers: \n", "    eq = qb.AddEquity(ticker)\n", "    tickers_dict[ticker] = eq\n", "    \n", "print(\"Loading historical data...\")\n", "# get historical prices\n", "history = qb.History(tickers, PARAM.Start, PARAM.End, PARAM.Resolution)\n", "\n", "print(\"Preparing historical data...\")\n", "# Unpack dataframe\n", "Open = history['open'].unstack(level=0)\n", "Close = history['close'].unstack(level=0)\n", "High = history['high'].unstack(level=0)\n", "Low = history['low'].unstack(level=0)\n", "\n", "# create data object\n", "close = Data(Close)\n", "print(\"Done \\n\")\n", "print(\"-\"*30)\n", "print(f\"{len(close)} datapoints loaded for symbols: \\n {list(close.columns)}\")"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["# initial plot \n", "\n", "plt.figure()\n", "(close.prices / close.prices.iloc[0]).plot(figsize=(20,10))\n", "plt.title(f\"Price Percentage Change\")\n", "plt.grid()\n", "\n", "sym1, sym2 = 'IGV', 'IYW'\n", "eq1, eq2 = tickers_dict[sym1].Symbol, tickers_dict[sym2].Symbol\n", "\n", "plt.figure()\n", "(np.log(close.prices[eq1]) - np.log(close.prices[eq2])).plot(figsize=(20,10), marker='x')\n", "plt.title(f\"{sym1} - {sym2}\")\n", "\n", "plt.figure()\n", "plt.scatter(np.log(close.prices[eq1]), np.log(close.prices[eq2]))\n", "plt.title(f\"Scatter plot of price series {eq1} vs {eq2}\")\n", "\n", "plt.figure(figsize=(20,10))\n", "plt.scatter(close.returns[eq1], close.returns[eq2])\n", "plt.title(f\"Scatter plot of returns series {eq1} vs {eq2}\")"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": ["# fit regression line to price series\n", "from sklearn import linear_model \n", "\n", "p1 = close.returns[eq1].dropna().to_numpy().reshape(-1,1)\n", "p2 = close.returns[eq2].dropna().to_numpy().reshape(-1,1)\n", "\n", "reg_model = linear_model.LinearRegression().fit(p1, p2)\n"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": ["# regression model results + plot \n", "msg =\\\n", "f'''Linear Regression \n", "Y = {reg_model.intercept_[0]} + {reg_model.coef_[0][0]} X\n", "R^2 : {reg_model.score(p1,p2)}'''\n", "print(msg)\n", "\n", "\n", "\n", "plt.figure(figsize=(20,10))\n", "plt.scatter(p1, p2, marker='x')\n", "\n", "xmin, xmax = plt.xlim()\n", "w = 0.01\n", "X = np.arange(xmin, xmax, w)\n", "Y = reg_model.intercept_[0] + X * reg_model.coef_[0][0]\n", "\n", "plt.plot(X, Y)"]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": ["# lets do a simple simulation of the exposure that we will end up with when we use regression\n", "\n", "unit = 10\n", "weight = reg_model.coef_\n", "\n", "exposure1 = p1*unit\n", "exposure2 = p2*unit\n", "\n"]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(20,10))\n", "s = exposure2 - weight * exposure1\n", "\n", "mean = np.mean(s)\n", "stdev = np.std(s)\n", "print(f\"mean: {mean}, std-dev: {stdev}\")\n", "\n", "plt.plot(s)\n", "plt.hlines([0, mean+stdev, mean - stdev, mean + 2*stdev, mean - 2*stdev], 0, len(s))\n", "\n", "plt.figure(figsize=(10,10))\n", "plt.hist(s, bins=50)\n"]}, {"cell_type": "code", "execution_count": 99, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.8"}}, "nbformat": 4, "nbformat_minor": 2}