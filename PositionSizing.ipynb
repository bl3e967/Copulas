{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["![QuantConnect Logo](https://cdn.quantconnect.com/web/i/icon.png)\n", "<hr>"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["print(\"Hello World\") # just to check that the server is working properly. Sometimes even this doesn't work. "]}, {"cell_type": "markdown", "metadata": {}, "source": ["So above, we have made a simple method for achieving a dollar neutral position between two assets. \n", "Next, let's apply the algorithm on multiple asset pairs to devise an algorithm for position sizing. "]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["print(\"Loading QuantBook...\")\n", "qb = QuantBook()\n", "print(\"Done\")"]}, {"cell_type": "code", "execution_count": 29, "metadata": {}, "outputs": [], "source": ["import time\n", "import Model \n", "import config \n", "import random \n", "import itertools\n", "import Containers \n", "import multiprocessing as mp \n", "from datetime import datetime, timedelta\n", "from UtilFuncs import CorrelationFuncs\n", "from sklearn import linear_model \n", "\n", "_TICKERS = [\"SPY\",\"XLK\", \"VGT\", \"IYW\", \"IGV\"]\n", "MI_THRESHOLD = 0.9\n", "\n", "class Parameter():\n", "    def __init__(self,\n", "                resolution,\n", "                start_year, \n", "                start_month=1, \n", "                start_day=1,\n", "                n_years=0,\n", "                n_months=0, \n", "                n_days=0): \n", "        \n", "        self.Resolution = resolution\n", "        \n", "        end_year = start_year + n_years\n", "        end_month = start_month + n_months\n", "        end_day = start_day + n_days \n", "        self.Start = datetime(start_year,start_month,start_day,9,30,0)\n", "        self.End = datetime(end_year, end_month, end_day,16,30,0)\n", "\n", "class CopulasModel():\n", "    CORRELATION_THRESHOLD = 0.7\n", "    \n", "    def __init__(self):\n", "        # set the model type we are going to use\n", "        self.Model = Model.BivariateNonParametricCopula\n", "        self.Model.register_QC(qb) # WARNING: this will throw if we start logging inside models. \n", "    \n", "    def _get_historical_data(self, param:\"Parameter\"):\n", "        PARAM = param \n", "\n", "        # Specify list of correlated tickers for S&P 500 \n", "        tickers = _TICKERS\n", "\n", "        # register tickers to quantbook\n", "        for ticker in tickers: \n", "            qb.AddEquity(ticker)\n", "\n", "        print(\"Loading historical data...\")\n", "        # get historical prices\n", "        history = qb.History(tickers, PARAM.Start, PARAM.End, PARAM.Resolution)\n", "\n", "        print(\"Preparing historical data...\")\n", "\n", "        # create data object\n", "        close = Containers.Data(history, \"close\")\n", "        print(\"Done\")\n", "        \n", "        return close\n", "\n", "    def initialise_models(self): \n", "        '''\n", "        Return a CopulaModel object for each asset data\n", "        '''\n", "        # parameters\n", "        START_YEAR = 2011\n", "        START_MONTH = 1\n", "        START_DAY = 1\n", "        N_YEARS = 5\n", "        N_MONTHS = 0\n", "        N_DAYS = 0\n", "        RESOLUTION = Resolution.Daily\n", "        self.PARAM = Parameter(RESOLUTION, START_YEAR, START_MONTH, START_DAY,\n", "                          N_YEARS, N_MONTHS, N_DAYS)\n", "\n", "        # initialise dictionary for containing copula models\n", "        self.copulas = Containers.ModelContainer()\n", "\n", "        self.history = self._get_historical_data(self.PARAM)\n", "\n", "        # Find the pairs that satisfy our correlation criteria\n", "        # Criteria: Kendall Tau correlation > threshold \n", "        corr = self.history.get_correlations()\n", "        pairs_dict = CorrelationFuncs.correlation_above_thresh(corr, self.CORRELATION_THRESHOLD)\n", "\n", "        # fit the model\n", "        print(\"Fitting model\")\n", "        print(f\"Multiprocessing: {config.ModelParameters.FIT_MULTIPROCESS}\")\n", "        model_generator = Model.ModelFactory() \n", "        if not config.ModelParameters.FIT_MULTIPROCESS: \n", "            t = time.time()\n", "            for pair in pairs_dict.keys():\n", "                data_packet1 = self.history.get_returns(pair[0])\n", "                data_packet2 = self.history.get_returns(pair[1])\n", "                copula_model = model_generator.get_model(data_packet1, data_packet2)\n", "                self.copulas[pair] = copula_model\n", "            elapsed = time.time() - t\n", "            print(f\"{elapsed}s taken to fit {len(pairs_dict)} models\")\n", "        else:\n", "            # allocate cpu resource \n", "            num_workers = len(pairs_dict) if mp.cpu_count() > len(pairs_dict) else mp.cpu_count()\n", "            print(f\"Using {num_workers} processses to fit {len(pairs_dict)} models\")\n", "\n", "            # dispatch workers from pool\n", "            async_results = []\n", "            with mp.Pool() as pool: \n", "                for pair in pairs_dict.keys():\n", "                    data_packet1 = self.history.get_returns(pair[0])\n", "                    data_packet2 = self.history.get_returns(pair[1])\n", "                    get_proc = pool.apply_async(func=model_generator.get_model, \n", "                                                args=(data_packet1, data_packet2))\n", "                    async_results.append((pair, get_proc))\n", "\n", "                # wait for pool to return results\n", "                t = time.time()\n", "                for res in async_results:\n", "                    pair, model_getter = res\n", "                    copula_model = model_getter.get()\n", "                    self.copulas[pair] = copula_model\n", "                elapsed = time.time() - t   \n", "\n", "        print(f\"{elapsed}s taken to fit {len(pairs_dict)} models\")\n", "    \n", "    def get_scaling_factor(self, pair):\n", "        sym1, sym2 = pair\n", "        ret1 = self.history.returns[sym1].to_numpy().reshape(-1,1)\n", "        ret2 = self.history.returns[sym2].to_numpy().reshape(-1,1)\n", "        \n", "        reg_model = linear_model.LinearRegression().fit(ret1, ret2)\n", "        \n", "        plt.scatter(ret1, ret2)\n", "        return reg_model.coef_[0][0]\n"]}, {"cell_type": "code", "execution_count": 30, "metadata": {}, "outputs": [], "source": ["##############################################\n", "####### THIS SHOULD ONLY BE CALLED ONCE ######\n", "##############################################\n", "model = CopulasModel()\n", "model.initialise_models()"]}, {"cell_type": "code", "execution_count": 31, "metadata": {}, "outputs": [], "source": ["##############################################\n", "#######  LOAD HISTORICAL DATA FOR TEST  ######\n", "##############################################\n", "print(\"Loading test data\")\n", "NUM_TRADING_DAYS = timedelta(days=3)\n", "history = qb.History(_TICKERS, model.PARAM.End, model.PARAM.End + NUM_TRADING_DAYS)\n", "data = Containers.Data(history, \"close\")\n", "print(\"Done\")"]}, {"cell_type": "code", "execution_count": 36, "metadata": {}, "outputs": [], "source": ["def long_or_short(x):\n", "    if x > MI_THRESHOLD:\n", "        return -1\n", "    elif x < 1 - MI_THRESHOLD:\n", "        return 1\n", "    else:\n", "        return 0\n", "\n", "# for pair in model.copulas.keys():\n", "pair = list(model.copulas.keys())[2]\n", "sym1, sym2 = pair\n", "print(f\"sym1:{sym1} sym2:{sym2}\")\n", "\n", "# calculate marginals series\n", "u = model.copulas[pair].price_to_marginal(price=data.returns[sym1], symbol=sym1)\n", "v = model.copulas[pair].price_to_marginal(price=data.returns[sym2], symbol=sym1)\n", "\n", "grid_width = 0.01\n", "mi_calculator = model.copulas[pair].mispricing_index\n", "marginals = pd.DataFrame({\"u\":u, \"v\":v}, index=data.returns.index)\n", "t = time.time()\n", "marginals[[\"MI_u\", \"MI_v\"]] = pd.DataFrame(marginals.apply(lambda x: mi_calculator(x[\"u\"], x[\"v\"], grid_width), axis=1).tolist(), index=data.index[1:])\n", "elapsed = time.time() - t\n", "print(f\"elapsed:{elapsed}s\")\n", "\n", "# generate trading signals\n", "marginals[[\"trade_u\", \"trade_v\"]] = marginals[[\"MI_u\", \"MI_v\"]].applymap(long_or_short)\n", "# don't trade if only one leg has fired\n", "marginals.loc[np.abs(marginals[\"trade_u\"]) + np.abs(marginals[\"trade_v\"])==1] = 0 \n", "\n", "prices = data._timeseries[list(pair)]\n", "prices.join(marginals)"]}, {"cell_type": "code", "execution_count": 37, "metadata": {"scrolled": true}, "outputs": [], "source": ["def plot_performance_cumulative_trades():\n", "    SCALING_FACTOR = model.get_scaling_factor(pair)\n", "    TRADE_SIZE = 100\n", "\n", "    timeseries = data._timeseries[list(pair)]\n", "    timeseries = prices.join(marginals)\n", "    timeseries[\"pratio\"] = timeseries[pair[0]] / timeseries[pair[1]]\n", "\n", "    # price change over time\n", "    timeseries[[\"pchange_v\",\"pchange_u\"]] = timeseries[list(pair)] - timeseries[list(pair)].iloc[0]\n", "    timeseries[\"scaled_pchange_v\"] = timeseries[\"pchange_v\"]*SCALING_FACTOR\n", "    timeseries[\"scaled_pchange_u\"] = timeseries[\"pchange_u\"]\n", "\n", "    # position over time\n", "    timeseries[[\"cum_sig_u\",\"cum_sig_v\"]] = timeseries[[\"trade_u\",\"trade_v\"]].cumsum()\n", "    timeseries[\"position_u\"] = timeseries[\"cum_sig_u\"]*timeseries[pair[0]]*TRADE_SIZE\n", "    timeseries[\"position_v\"] = \\\n", "        timeseries[\"cum_sig_v\"]*timeseries[pair[1]]*np.round(TRADE_SIZE*timeseries.pratio*SCALING_FACTOR**-1)\n", "    timeseries[\"net_exposure\"] = timeseries.position_u + timeseries.position_v\n", "\n", "    # price change over trading period\n", "    timeseries[\"pchange_u\"] = timeseries[pair[0]] - timeseries[pair[0]].iloc[0]\n", "    timeseries[\"pchange_v\"] = timeseries[pair[1]] - timeseries[pair[1]].iloc[0]\n", "\n", "    # pnl\n", "    timeseries[\"pnl_u\"] = timeseries.pchange_u * timeseries.position_u\n", "    timeseries[\"pnl_v\"] = timeseries.pchange_v * timeseries.position_v\n", "    timeseries[\"pnl\"] = timeseries.pnl_u + timeseries.pnl_v\n", "\n", "    # plot\n", "    fig, ax = plt.subplots(5, figsize=(20,30))\n", "    timeseries[[\"pchange_u\", \"pchange_v\"]].plot(ax=ax[0])\n", "    timeseries[[\"pnl_u\", \"pnl_v\", \"pnl\"]].plot(ax=ax[1])\n", "    timeseries[[\"position_u\", \"position_v\",\"net_exposure\"]].plot(ax=ax[2])\n", "    timeseries[[\"scaled_pchange_u\", \"scaled_pchange_v\"]].plot(ax=ax[3])\n", "    (timeseries[\"scaled_pchange_u\"] - timeseries[\"scaled_pchange_v\"]).plot(ax=ax[4])\n", "\n", "    for axis in ax:\n", "        axis.grid()\n", "plot_performance_cumulative_trades()"]}, {"cell_type": "code", "execution_count": 38, "metadata": {}, "outputs": [], "source": ["def plot_performance_single_trades():\n", "    SCALING_FACTOR = model.get_scaling_factor(pair)\n", "    TRADE_SIZE = 100\n", "\n", "    timeseries = data._timeseries[list(pair)]\n", "    timeseries = prices.join(marginals)\n", "    timeseries[\"pratio\"] = timeseries[pair[0]] / timeseries[pair[1]]\n", "\n", "    # price change over time\n", "    timeseries[[\"pchange_v\",\"pchange_u\"]] = timeseries[list(pair)] - timeseries[list(pair)].iloc[0]\n", "    timeseries[\"scaled_pchange_v\"] = timeseries[\"pchange_v\"]*SCALING_FACTOR\n", "    timeseries[\"scaled_pchange_u\"] = timeseries[\"pchange_u\"]\n", "\n", "    # position over time\n", "    timeseries[[\"cum_sig_u\",\"cum_sig_v\"]] = \\\n", "        timeseries[[\"trade_u\",\"trade_v\"]].cumsum().clip(lower=-1, upper=1)\n", "    timeseries[\"position_u\"] = timeseries[\"cum_sig_u\"]*timeseries[pair[0]]*TRADE_SIZE\n", "    timeseries[\"position_v\"] = \\\n", "        timeseries[\"cum_sig_v\"]*timeseries[pair[1]]*np.round(TRADE_SIZE*timeseries.pratio*SCALING_FACTOR**-1)\n", "    timeseries[\"net_exposure\"] = timeseries.position_u + timeseries.position_v\n", "\n", "    # price change over trading period\n", "    timeseries[\"pchange_u\"] = timeseries[pair[0]] - timeseries[pair[0]].iloc[0]\n", "    timeseries[\"pchange_v\"] = timeseries[pair[1]] - timeseries[pair[1]].iloc[0]\n", "\n", "    # pnl\n", "    timeseries[\"pnl_u\"] = timeseries.pchange_u * timeseries.position_u\n", "    timeseries[\"pnl_v\"] = timeseries.pchange_v * timeseries.position_v\n", "    timeseries[\"pnl\"] = timeseries.pnl_u + timeseries.pnl_v\n", "\n", "    # plot\n", "    fig, ax = plt.subplots(5, figsize=(20,30))\n", "    timeseries[[\"pchange_u\", \"pchange_v\"]].plot(ax=ax[0])\n", "    timeseries[[\"pnl_u\", \"pnl_v\", \"pnl\"]].plot(ax=ax[1])\n", "    timeseries[[\"position_u\", \"position_v\",\"net_exposure\"]].plot(ax=ax[2])\n", "    timeseries[[\"scaled_pchange_u\", \"scaled_pchange_v\"]].plot(ax=ax[3])\n", "    (timeseries[\"scaled_pchange_u\"] - timeseries[\"scaled_pchange_v\"]).plot(ax=ax[4])\n", "\n", "    for axis in ax:\n", "        axis.grid()\n", "\n", "plot_performance_single_trades()"]}, {"cell_type": "code", "execution_count": 40, "metadata": {}, "outputs": [], "source": ["import Iterators\n", "\n", "SCALING_FACTOR = model.get_scaling_factor(pair)\n", "TRADE_SIZE = 100\n", "\n", "timeseries = data._timeseries[list(pair)]\n", "timeseries = prices.join(marginals)\n", "timeseries[\"pratio\"] = timeseries[pair[0]] / timeseries[pair[1]]\n", "\n", "# price change over time\n", "timeseries[[\"pchange_v\",\"pchange_u\"]] = timeseries[list(pair)] - timeseries[list(pair)].iloc[0]\n", "timeseries[\"scaled_pchange_v\"] = timeseries[\"pchange_v\"]*SCALING_FACTOR\n", "timeseries[\"scaled_pchange_u\"] = timeseries[\"pchange_u\"]\n", "\n", "# position over time\n", "timeseries[\"cum_sig_u\"] = timeseries[\"trade_u\"].apply(Iterators.AbsValMaxOne())\n", "timeseries[\"cum_sig_v\"] = timeseries[\"trade_v\"].apply(Iterators.AbsValMaxOne())\n", "timeseries[\"position_u\"] = timeseries[\"cum_sig_u\"]*timeseries[pair[0]]*TRADE_SIZE\n", "timeseries[\"position_v\"] = \\\n", "    timeseries[\"cum_sig_v\"]*timeseries[pair[1]]*np.round(TRADE_SIZE*timeseries.pratio*SCALING_FACTOR**-1)\n", "timeseries[\"net_exposure\"] = timeseries.position_u + timeseries.position_v\n", "\n", "# price change over trading period\n", "timeseries[\"pchange_u\"] = timeseries[pair[0]] - timeseries[pair[0]].iloc[0]\n", "timeseries[\"pchange_v\"] = timeseries[pair[1]] - timeseries[pair[1]].iloc[0]\n", "\n", "# pnl\n", "timeseries[\"pnl_u\"] = timeseries.pchange_u * timeseries.position_u\n", "timeseries[\"pnl_v\"] = timeseries.pchange_v * timeseries.position_v\n", "timeseries[\"pnl\"] = timeseries.pnl_u + timeseries.pnl_v\n", "\n", "# plot\n", "fig, ax = plt.subplots(5, figsize=(20,30))\n", "timeseries[[\"pchange_u\", \"pchange_v\"]].plot(ax=ax[0])\n", "timeseries[[\"pnl_u\", \"pnl_v\", \"pnl\"]].plot(ax=ax[1])\n", "timeseries[[\"position_u\", \"position_v\",\"net_exposure\"]].plot(ax=ax[2])\n", "timeseries[[\"scaled_pchange_u\", \"scaled_pchange_v\"]].plot(ax=ax[3])\n", "(timeseries[\"scaled_pchange_u\"] - timeseries[\"scaled_pchange_v\"]).plot(ax=ax[3])\n", "timeseries[[\"cum_sig_u\", \"cum_sig_v\"]].plot(ax=ax[4])\n", "\n", "for axis in ax:\n", "    axis.grid()\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.8"}}, "nbformat": 4, "nbformat_minor": 2}