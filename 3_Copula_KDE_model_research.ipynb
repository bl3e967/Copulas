{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["![QuantConnect Logo](https://cdn.quantconnect.com/web/i/icon.png)\n", "<hr>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Copula KDE Model\n", "\n", "Here, we will research and develop a model for estimating Copula density from returns distributions. In the previous Jupyter notebook, the transformation method was used to estimate copula density for stock returns of the S&P 500 ETFs. This was done as in initial investigation to the feasibility of using this approach. \n", "\n", "As it has been established that using a KDE model may be appropriate, here we will try and develop a data pipeline, involving: \n", "* Preprocessing asset price data\n", "* Fitting a model to the data\n", "* Optimising the model\n", "    * What kernels are most effective\n", "    * How to quantitatively evaluate the performance of a model\n", "* Generating insights\n", "    * Lookback window for training\n", "    * Frequency of refitting the model to new data\n", "\n", "This will provide insights into the components necessary for building an alpha model. "]}, {"cell_type": "code", "execution_count": 80, "metadata": {}, "outputs": [], "source": ["#------------------------------------------------------------------------------------------\n", "# util objects \n", "#------------------------------------------------------------------------------------------\n", "from statsmodels.distributions.empirical_distribution import ECDF\n", "from copulas.bivariate.base import Bivariate\n", "from copulas.multivariate import GaussianMultivariate\n", "\n", "class Parameter():\n", "    def __init__(self,\n", "                resolution,\n", "                start_year, \n", "                start_month=1, \n", "                start_day=1,\n", "                n_years=0,\n", "                n_months=0, \n", "                n_days=0): \n", "        \n", "        self.Resolution = resolution\n", "        \n", "        end_year = start_year + n_years\n", "        end_month = start_month + n_months\n", "        end_day = start_day + n_days \n", "        self.Start = datetime(start_year,start_month,start_day,9,30,0)\n", "        self.End = datetime(end_year, end_month, end_day,16,30,0)\n", "    \n", "class Data():\n", "    def __init__(self, df):\n", "        self._df = df.dropna()\n", "        self.marginals = pd.DataFrame()\n", "        \n", "        self.init_data()\n", "        \n", "    def init_data(self): \n", "        self.get_marginals()\n", "    \n", "    @property \n", "    def prices(self):\n", "        return self._df\n", "    \n", "    @property\n", "    def returns(self):\n", "        return self._df.diff() \n", "    \n", "    @property\n", "    def columns(self):\n", "        return self._df.columns\n", "    \n", "    @property\n", "    def assets(self):\n", "        return self._df.columns\n", "    \n", "    def get_marginals(self):\n", "        for asset in self.assets: \n", "            self.marginals[asset] = self.fit_transform_ECDF(asset)\n", "        return self.marginals\n", "    \n", "    def fit_ECDF(self, asset=None):\n", "        '''\n", "            Return Emprical Culumlative Distribution fit to returns data\n", "            for the specified asset. If asset is None, then returns a dictionary \n", "            for all assets. \n", "        '''\n", "        if asset:\n", "            return ECDF(self.returns[asset])\n", "        else: \n", "            ecdf_dct = {}\n", "            for inst in self._df.columns:\n", "                ecdf_dct[inst] = ECDF(self.returns[inst])\n", "            return ecdf_dct\n", "    \n", "    def transform(self, model, asset=None):\n", "        '''Transform the data according to the model passed. '''\n", "        if asset:\n", "            return model(self.returns[asset])\n", "        else: \n", "            return self.returns.apply(model, axis=0)\n", "    \n", "    def fit_transform_ECDF(self, asset):\n", "        '''\n", "            Return the transformed returns data after fitting an ECDf to the data. \n", "        '''\n", "        ecdf = self.fit_ECDF(asset=asset)\n", "        return self.returns[asset].apply(ecdf)\n", "    \n", "    def plot(self, *args, **kwargs): \n", "        return self._df.plot(*args, **kwargs)\n", "    \n", "    def _get_corr_pair_desc(self, corr):\n", "        return (corr.where(np.triu(np.ones(corr.shape), k=1).astype(np.bool))\n", "                     .stack()\n", "                     .sort_values(ascending=False))\n", "    \n", "    def _get_max_corr_pair(self, corr): \n", "        sol = self._get_corr_pair_desc(corr)\n", "        col1 = self.columns[sol.index[sol == max(sol)].labels[0]].values[0]\n", "        col2 = self.columns[sol.index[sol == max(sol)].labels[1]].values[0]\n", "        return(col1, col2)\n", "    \n", "    def max_returns_corr_pair(self, method='kendall'):\n", "        '''\n", "            Returns a tuple pair of assets with highest correlation. \n", "        '''\n", "        corr = close.returns.corr(method=method)\n", "        max_pair = self._get_max_corr_pair(corr)\n", "        return max_pair\n", "    \n", "    def returns_corr(self, method='kendall'):\n", "        return close.returns.corr(method=method)\n", "    \n", "    def pairs_by_returns_correlation(self, method='kendall'):\n", "        return self._get_corr_pair_desc(self.returns_corr(method=method))"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["#------------------------------------------------------------------------------------------\n", "# Copula Model\n", "#------------------------------------------------------------------------------------------\n", "from scipy.stats import norm\n", "import statsmodels.api as sm\n", "from collections import namedtuple\n", "\n", "_KDEMODEL = namedtuple(\"KDEMODEL\", [\"model\", \"parameters\"])\n", "\n", "_STATSLIB_KDE_MULTIVARIATE_PARAMS = {\n", "    \"var_type\" : \"cc\", \n", "    \"bw\" : ['normal_reference', 'cv_ml', 'cv_ls']\n", "}\n", "\n", "class KDECopula():\n", "    def __init__(self, data):\n", "        self._data = np.array(data)\n", "        self._u = data[:,0]\n", "        self._v = data[:,1]\n", "        self._check_input(data)\n", "        \n", "        self._models = {\n", "            \"statslib_KDEMultivariate\" : _KDEMODEL(model=sm.nonparametric.KDEMultivariate,\n", "                                                   parameters=_STATSLIB_KDE_MULTIVARIATE_PARAMS)\n", "        }\n", "    \n", "    @staticmethod\n", "    def _check_input(data):\n", "        dim = data.shape\n", "        if len(dim) != 2: \n", "            raise ValueError(\"Input shape {}, expected (n,2)\".format(dim))\n", "        \n", "        if dim[-1] != 2: \n", "            raise ValueError(\"Input is {} dimensional. Expected 2D.\".format(dim[-1]))\n", "    \n", "    @staticmethod\n", "    def transform(data:\"np.array\"):\n", "        '''Transform from [0,1]^2 domain to R^2 domain using Gaussian method'''\n", "        data_raw_ = norm.ppf(data)\n", "        data_ = np_remove_inf(data)\n", "        return data_\n", "    \n", "    def fit(self, data:\"np.array\"): \n", "        '''Fit a KDE model to the input data'''\n", "        self._check_input(data)\n", "        \n", "        \n", "    \n", "    def transform_fit(self):\n", "        pass \n", "        \n", "        \n", "    \n", "    \n", "    "]}, {"cell_type": "code", "execution_count": 81, "metadata": {}, "outputs": [], "source": ["#------------------------------------------------------------------------------------------\n", "# model comparison criteria\n", "#------------------------------------------------------------------------------------------\n", "def AIC(log_lik, n_params):\n", "    '''\n", "        AIC = 2k - 2*ln(L)\n", "        Args: \n", "            log_lik: total log likelihood over all sampoles\n", "            n_samples: number of samples\n", "            n_params: number of parameters\n", "    '''\n", "    return 2 * n_params - 2 * log_lik\n", "\n", "def BIC(log_lik, n_samples, n_params):\n", "    '''\n", "        BIC = k*ln(N) - 2*ln(L)\n", "        where \n", "            k = number of parameters\n", "            N = number of samples \n", "            L = likelihood\n", "        Args: \n", "            log_lik: total log likelihood over all sampoles\n", "            n_samples: number of samples\n", "            n_params: number of parameters\n", "    '''\n", "    return k * np.log(n_samples) - 2 * log_lik"]}, {"cell_type": "code", "execution_count": 82, "metadata": {}, "outputs": [], "source": ["#------------------------------------------------------------------------------------------\n", "# Util functions\n", "#------------------------------------------------------------------------------------------\n", "def np_remove_nan(x): \n", "    return x[np.logical_not(np.isnan(x).any(axis=1))]\n", "\n", "def np_remove_inf(x):\n", "    return x[np.logical_not(np.isinf(x).any(axis=1))]"]}, {"cell_type": "code", "execution_count": 83, "metadata": {}, "outputs": [], "source": ["# QuantBook Analysis Tool \n", "# For more information see [https://www.quantconnect.com/docs/research/overview]\n", "qb = QuantBook()\n", "\n", "# parameters\n", "START_YEAR = 2005\n", "START_MONTH = 1\n", "START_DAY = 1\n", "N_YEARS = 10\n", "N_MONTHS = 0\n", "N_DAYS = 0\n", "RESOLUTION = Resolution.Daily\n", "PARAM = Parameter(RESOLUTION, START_YEAR, START_MONTH, START_DAY,\n", "                  N_YEARS, N_MONTHS, N_DAYS)\n", "\n", "# Specify list of correlated tickers for S&P 500 \n", "sp500_tickers = [\"SPY\",\"XLK\", \"VGT\", \"IYW\", \"IGV\"]\n", "djia_tickers = [\"DIA\", \"IYY\", \"DDM\"]\n", "tickers = sp500_tickers\n", "\n", "# register tickers to quantbook\n", "for ticker in tickers: \n", "    qb.AddEquity(ticker)\n", "    \n", "# get historical prices\n", "history = qb.History(tickers, PARAM.Start, PARAM.End, PARAM.Resolution)\n", "\n", "# Unpack dataframe\n", "Open = history['open'].unstack(level=0)\n", "Close = history['close'].unstack(level=0)\n", "High = history['high'].unstack(level=0)\n", "Low = history['low'].unstack(level=0)\n", "\n", "# create data object - We use close by default\n", "close = Data(Close)"]}, {"cell_type": "code", "execution_count": 84, "metadata": {}, "outputs": [], "source": ["#---------------------------------------------------------------------------------------------------\n", "# Data Preprocessing\n", "#---------------------------------------------------------------------------------------------------\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.8"}}, "nbformat": 4, "nbformat_minor": 2}